{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run exploratory code and print graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "from find_formality import add_context_sentences, find_formality_dutch, filter_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code running on the whole iwslt2017_context en-nl dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  2.71ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30028"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset.to_csv('annotations/annotations_bjurn_20.csv')\n",
    "\n",
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding context sentences: 100%|██████████| 237240/237240 [02:50<00:00, 1387.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# load the iwslt2017 dataset and do the pre-processing\n",
    "dataset = load_dataset(\n",
    "    'gsarti/iwslt2017_context', 'iwslt2017-en-nl', split='train'\n",
    ")  # change to train after testing\n",
    "# print(f'Total amount of rows in train set: {len(dataset)}')\n",
    "\n",
    "# add context fields to the dataset\n",
    "dataset = add_context_sentences(dataset)\n",
    "\n",
    "# filter the dataset for formality\n",
    "formality_words = ['u', 'je', 'jij', 'jou', 'jouw', 'uw', 'jullie']\n",
    "# formality_words = ['u', 'jij', 'jou', 'jouw', 'uw', 'jullie']\n",
    "word_boundary = r'\\b'\n",
    "formality_regex = fr'{\"|\".join([word_boundary + word + word_boundary for word in formality_words])}'\n",
    "\n",
    "# filter the dataset on formality examples\n",
    "dataset = dataset.filter(lambda x: find_formality_dutch(formality_regex, x))\n",
    "\n",
    "# remove sentences without enough context or with multiple formality words\n",
    "dataset = dataset.filter(lambda x: filter_examples(formality_regex, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['doc_id', 'seg_id', 'translation', 'context'],\n",
       "    num_rows: 29478\n",
       "})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u': 1349, 'je': 22886, 'jij': 624, 'jou': 282, 'jouw': 240, 'uw': 118, 'jullie': 3979}\n"
     ]
    }
   ],
   "source": [
    "formality_word_count = {formality_word: 0 for formality_word in formality_words}\n",
    "\n",
    "for example in dataset:\n",
    "    formality_word_count[re.search(formality_regex, example['translation']['nl'], re.IGNORECASE).group().lower()] += 1\n",
    "\n",
    "print(formality_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code running on the annotated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['doc_id', 'seg_id', 'translation', 'context'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the annotated dataset\n",
    "dataset_20 = load_from_disk('annotations/annotations_nl')\n",
    "\n",
    "dataset_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u': 5, 'je': 1, 'jij': 3, 'jou': 1, 'jouw': 1, 'uw': 0, 'jullie': 9}\n"
     ]
    }
   ],
   "source": [
    "formality_word_count = {formality_word: 0 for formality_word in formality_words}\n",
    "\n",
    "for idx, example in enumerate(dataset_20):\n",
    "    formality_word_count[re.search(formality_regex, example['translation']['nl'], re.IGNORECASE).group(0).lower()] += 1\n",
    "\n",
    "print(formality_word_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
